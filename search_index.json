[["index.html", "OCA Data Sharing Practicals Chapter 1 Introduction", " OCA Data Sharing Practicals Chapter 1 Introduction This repository contains two training documents for the OCA Data Sharing Platform: Chapter 2: Data dictionaries covers the production of data dictionaries to accompany datasets that will be shared Chapter 3: Pseudonymization covers techniques for assessing and limiting disclosure risk when preparing datasets to be share "],["data-dict.html", "Chapter 2 Data dictionaries 2.1 Objectives 2.2 Background 2.3 Dictionary format 2.4 The datadict package 2.5 Exercises", " Chapter 2 Data dictionaries 2.1 Objectives Learn to: prepare an OCA-style data dictionary, starting from either a raw dataset or a ODK/Kobo dictionary compare datasets and corresponding data dictionaries to ensure completeness and validity 2.2 Background Documenting the variables in a dataset is a crucial part of data management and ensures that a dataset is interpretable by researchers who were not directly involved in study design or data collection. Whereas data files will generally contain codenames for variables (e.g. patagegrp for “Patient’s age group”), and sometimes also coded data values, the data dictionary describes each variable and the set of possible values in plain language that is more broadly interpretable. Data collection platforms such as Kobo, REDCap, and OpenClinica have their own specialized data dictionary format. To facilitate dataset and data dictionary validation, the OCA Data Sharing Platform uses its own standardized dictionary format, defined in the next section. 2.3 Dictionary format Every dataset shared or archived on the OCA platform must have an accompanying data dictionary that includes, at a minimum, the fields described below. Each variable in the dataset (i.e. each column) must have a dictionary entry for each of the required fields. Required field Description Example entry variable_name Variable name (i.e. exact column name within the corresponding dataset) “sample_type” short_label Short phrase describing the variable in words “Type of laboratory sample collected” origin Was the variable a part of the original data collection instrument (option “original”), or was it later derived (option “derived”) “original” type Variable type (options: “Numeric”, “Date”, “Time”, “Datetime”, “Coded list”, or “Free text”) “Coded list” choices The list of options (pairs of codes and labels) corresponding to a variable of type “Coded list”. “1, Blood | 2, Nasal swab | 3, Throat swab | 4, Other” 2.4 The datadict package The R package datadict contains a variety of functions to aid in the preparation of an OCA-style data dictionary: dict_from_data(): prepare a dictionary template from a raw dataset dict_from_odk(): prepare a dictionary template from an ODK/Kobo dictionary dict_from_redcap(): prepare a dictionary template from a REDCap dictionary valid_dict(): verify that a dictionary is consistent with the OCA format valid_data(): verify that a dataset corresponds to its associated data dictionary Note that dictionary templates produces by the dict_from_ functions may still require further processing by the user (e.g. with additional R scripts, or by hand in Excel). 2.5 Exercises This repository includes an example dataset based on a mortality survey. Load the dataset and corresponding ODK data dictionary using the example code below, and work through the following exercises using functions from the datadict package where possible. library(rio) library(here) # import dataset dat &lt;- rio::import(here(&quot;data/mortality_survey_simple_data.xlsx&quot;), setclass = &quot;tbl&quot;) # import ODK dictionary (note the main dictionary and multiple-choice options are in separate sheets) odk_survey &lt;- rio::import(here(&quot;data/mortality_survey_simple_kobo.xlsx&quot;), sheet = &quot;survey&quot;, setclass = &quot;tbl&quot;) odk_choices &lt;- rio::import(here(&quot;data/mortality_survey_simple_kobo.xlsx&quot;), sheet = &quot;choices&quot;, setclass = &quot;tbl&quot;) 2.5.1 Exercise 1 With the datadict package we can prepare a dictionary template either from the raw dataset (using dict_from_data()) or from the ODK dictionary (using dict_from_odk()). Try both approaches separately and compare the resulting dictionary templates. What are some differences? Can you guess why these differences are occurring? 2.5.2 Exercise 2 When producing a dictionary template using dict_from_data(), the variable type is determined by the class of the original column (e.g. character, numeric, Date). The column classes that are read in by e.g. rio::import() might not always correspond to the variable types that we have in mind (e.g. numbers, dates, and times are sometimes read in as class “character”). Where necessary, transform the columns of dat using functions like as.numeric() or as.Date() and then produce another dictionary template using dict_from_data(). What are the differences that remain between this dictionary template and the template derived from the ODK dictionary? 2.5.3 Exercise 3 Examine the options for the ‘Coded list’ type variables in the dictionary produced in exercise 2, and compare these to the corresponding options produced by dict_from_odk(). Why does the dictionary produced by dict_from_data() have fewer ‘Coded list’ options for some variables? Does this matter in terms of data sharing? Hint: check out the function datadict::coded_options() to extract a long-form table of Coded list variables and corresponding options from a dictionary. 2.5.4 Exercise 4 Use the function valid_dict() to check that the dictionary you produced in Exercise 2 complies with the OCA standard. Assuming it does, edit the dictionary so that it fails at least two of the checks implemented by valid_dict(). 2.5.5 Exercise 5 Use the function valid_data() to check for consistency between the dataset and dictionary produced in Exercise 2. Assuming all checks pass, edit the dataset so that it fails at least two of the checks implemented by valid_data(). "],["pseudonym.html", "Chapter 3 Pseudonymization 3.1 Objectives 3.2 Background 3.3 Typical workflow 3.4 Exercise", " Chapter 3 Pseudonymization 3.1 Objectives Learn to: assess the variables in a dataset for disclosure risk and utility implement pseudonymization procedures, where necessary, to limit disclosure risk ensure that a final dataset meets all data-sharing requirements 3.2 Background 3.2.1 Disclosure When a person or organization recognizes or learns something that they did not already know about another identifiable person or organization through released data. This might occur through: spontaneous recognition (i.e. someone with knowledge of the sampled population recognizes a unique or particular combination of data values) record matching/linkage with other existing datasets (e.g. population registers, electoral rolls, data from specialized firms) 3.2.2 Identifiers Direct identifiers: variables that unambiguously reveal a person’s identity (e.g. name, passport number, phone number, physical address, email address) Indirect identifiers: variables that contain information that, when combined with other variables, could lead to re-identification (e.g. sex, age, marital status, occupation). Note potential for elevated identifiability risk from extreme values of continuous variables (height, income, number of children, land area). 3.2.3 k-anonymity A measure of re-identification risk for discrete variables. k = the number of records in a dataset containing a certain combination of indirect identifiers (e.g. how many records with sex = “male” and age_group = “40-49 years” ?). Higher value of k means lower re-identification risk, because higher k means more records in the dataset with the same combination of indirect identifiers. 3.2.4 Pseudonymization Methods used to transform a dataset to achieve an “acceptable level” of re-identification / disclosure risk. Two types of methods: Non-perturbative: suppression (remove entire variables, or specific records or values) or aggregation (aggregate levels of a variable to reduce uniqueness) Perturbative: shuffle values or add noise to a variable while preserving desired statistical properties 3.3 Typical workflow Select a threshold value of k-anonymity that will be the minimum acceptable value for combinations of indirect identifiers within the released dataset (e.g. k = 5). Assess re-identification risk of each variable (e.g. direct identifier, indirect identifier, non-identifying). Assess utility of each variable for analysis (e.g. high, low, uncertain). Withhold variables classified as direct identifiers (e.g. name, phone number, address). Consider withholding other variables with low utility and non-zero re-identification risk. Merge groups of related indirect identifiers, where possible. E.g. If dataset contains two age-related variables age_in_years and age_in_months, merge these two variables into a new derived variable age, and withhold the original variables. Review all unique values of ‘free-text’ type variables to ensure they do not contain identifying details. Aggregate or withhold as necessary. Discretise any indirect identifiers that are continuous variables (e.g. height in cm -&gt; discrete height categories). Assess re-identification risk criterion (i.e. k-anonymity) using all indirect identifiers. Pseudonymize indirect identifiers to limit re-identification risk (e.g. aggregate, withhold). Repeat steps 8 and 9 until the given risk criterion is met. Ensure that the final pseudonymized dataset and dictionary meet all data-sharing requirements. 3.4 Exercise This repository includes an example dataset based on a mortality survey. Load the dataset and pre-prepared data dictionary using the example code below, and use them to work through the pseudonymization workflow described above. library(rio) library(here) # import dataset and prepared data dictionary dat &lt;- rio::import(here(&quot;data/mortality_survey_simple_data.xlsx&quot;), setclass = &quot;tbl&quot;) dict &lt;- rio::import(here(&quot;data/mortality_survey_simple_dict_pre_pseudonym.xlsx&quot;), setclass = &quot;tbl&quot;) As you make your way through the pseudonymization workflow, answer the following questions: (1) Which variables, if any, did you assess as either direct or indirect identifiers? (2) Despite not being completely familiar with the original study, were you able to assess any variables as being of low utility for analysis? If so, what actions did you (3) Did you find any groups of related variables that you decided to merge into a new derived variable? (4) In your assessment of free-text variables, did you notice any values that were potentially identifying? If so, what actions did you take? (5) In your initial application of Step 6 of the pseudonymization work flow, were there any combinations of indirect identifiers yielding values of k below your pre-selected threshold? If so, what action did you take? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
